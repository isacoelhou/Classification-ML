{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importações para todo o código, incluso método para \"bagunçar\" os dados, treino e cálculo de acurácia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impotação do classificador KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importação do classificador MLP junto ao Perceptron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importação para o classificador Decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importação para o classificador SVC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importação para o classificador Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicio do código para importação da base de dados e para realização da divisão estratificada dos seguintes conjuntos: Treino (50%), validação (25%) e Teste (25%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.read_csv(\"../Dataset/studentp.csv\")\n",
    "\n",
    "dados = shuffle(dados)\n",
    "\n",
    "X = dados.iloc[:,:-1]\n",
    "Y = dados.iloc[:,-1]\n",
    "\n",
    "x_treino,x_temp,y_treino,y_temp=train_test_split(X,Y,test_size=0.5,stratify=Y)\n",
    "x_validacao,x_teste,y_validacao,y_teste=train_test_split(x_temp,y_temp,test_size=0.5, stratify = y_temp)\n",
    "\n",
    "print(\"Treino\")\n",
    "x_treino.info()\n",
    "y_treino.info()\n",
    "\n",
    "print(\"\\nValidação\")\n",
    "x_validacao.info()\n",
    "y_validacao.info()\n",
    "\n",
    "print(\"\\nTeste\")\n",
    "x_teste.info()\n",
    "y_teste.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicio do código para verificação de melhores parâmetros para classificador KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxa_de_erro = []\n",
    "metrica = []\n",
    "maior = -1\n",
    "for j in (\"distance\",\"uniform\"):\n",
    "  for i in range (1,20):\n",
    "    KNN = KNeighborsClassifier(n_neighbors=i,weights=j)\n",
    "    KNN.fit(x_treino,y_treino)\n",
    "    opiniao = KNN.predict(x_validacao)\n",
    "\n",
    "    taxa_de_erro.append(np.mean(opiniao!=y_validacao))\n",
    "    metrica.append(j)\n",
    "    Acc = accuracy_score(y_validacao, opiniao)\n",
    "\n",
    "    print(\"K: \",i,\" Métrica: \",j,\" Acc: \",Acc)\n",
    "    if (Acc > maior):\n",
    "      maior = Acc\n",
    "      melhor_k_acc = i\n",
    "      Melhor_metrica = j\n",
    "\n",
    "\n",
    "print(\"\\nMelhor configuração para o KNN com relação a taxa de erro sobre a validação:\")\n",
    "melhor_k_te=np.argmin(taxa_de_erro)+1\n",
    "print(\"\\nMelhor K:\", melhor_k_te,\" metrica\", metrica[melhor_k_te], \"\\n\\n\")\n",
    "\n",
    "print(\"\\nMelhor configuração para o KNN com relação a acurácia sobre a validação\")\n",
    "print(\"K: \",melhor_k_acc,\" Métrica: \",Melhor_metrica,\" Acc\",maior)\n",
    "\n",
    "print(\"\\n\\nDesempenho sobre o conjunto de teste\")\n",
    "\n",
    "KNN_TE = KNeighborsClassifier(n_neighbors=melhor_k_te,weights=metrica[melhor_k_te])\n",
    "KNN_ACC = KNeighborsClassifier(n_neighbors=melhor_k_acc,weights=Melhor_metrica)\n",
    "\n",
    "KNN_TE.fit(x_treino,y_treino)\n",
    "KNN_ACC.fit(x_treino,y_treino)\n",
    "\n",
    "opiniao_TE = KNN_TE.predict(x_teste)\n",
    "opiniao_ACC = KNN_ACC.predict(x_teste)\n",
    "\n",
    "print(\"\\nCom base na Taxa de Erro:\\nK: \",melhor_k_te,\"Métrica: \", metrica[melhor_k_te], \" Acurácia sobre o testeA: \",accuracy_score(y_teste, opiniao_TE))\n",
    "print(\"\\nCom base na Acurácia:\\nK: \",melhor_k_acc,\"Métrica: \", Melhor_metrica, \" Acurácia sobre o teste: \",accuracy_score(y_teste, opiniao_ACC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicio do código para verificação de melhores parâmetros para classificador Decision Tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maior = -1\n",
    "for j in (\"entropy\",\"gini\"):  #criterion\n",
    "  for i in range (1,20):      #max_depth\n",
    "    for k in range (1,20):    #min_samples_leaf\n",
    "      for l in range (2,20):  #min_samples_split\n",
    "        for m in ('best','random'): #splitter\n",
    "          AD = DecisionTreeClassifier(criterion=j,max_depth=i,min_samples_leaf=k,min_samples_split=l,splitter=m)\n",
    "          AD.fit(x_treino,y_treino)\n",
    "          opiniao = AD.predict(x_validacao)\n",
    "          Acc = accuracy_score(y_validacao, opiniao)\n",
    "          print(\"Criterion: \",j,\" max_depth: \",i,\" min_samples_leaf: \",k,\" min_samples_split: \",l,\" splitter: \",m,\" Acc: \",Acc)\n",
    "          if (Acc > maior):\n",
    "            maior = Acc\n",
    "            crit = j\n",
    "            md = i\n",
    "            msl = k\n",
    "            mss = l\n",
    "            split = m\n",
    "\n",
    "print(\"\\nMelhor configuração para a AD\")\n",
    "print(\"Criterion: \",crit,\" max_depth: \",md,\" min_samples_leaf: \",msl,\" min_samples_split: \",mss,\" splitter: \",split,\" Acc: \",maior)\n",
    "\n",
    "print(\"\\n\\nDesempenho sobre o conjunto de teste\")\n",
    "AD = DecisionTreeClassifier(criterion=crit,max_depth=md,min_samples_leaf=msl,min_samples_split=mss,splitter=split)\n",
    "AD.fit(x_treino,y_treino)\n",
    "opiniao = AD.predict(x_teste)\n",
    "print(\"Acurácia sobre o teste: \",accuracy_score(y_teste, opiniao))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicio do código para verificação de melhores parâmetros para classificador SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maior = -1\n",
    "for k in (\"linear\", \"poly\", \"rbf\", \"sigmoid\"):  #kernel\n",
    "  for i in (0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0):  #custo\n",
    "    SVM = SVC(kernel=k,C=i)\n",
    "    SVM.fit(x_treino,y_treino)\n",
    "    opiniao = SVM.predict(x_validacao)\n",
    "    Acc = accuracy_score(y_validacao, opiniao)\n",
    "    print(\"Kernel: \",k,\" C: \",i,\" Acc: \",Acc)\n",
    "    if (Acc > maior):\n",
    "      maior = Acc\n",
    "      ker = k\n",
    "      custo = i\n",
    "\n",
    "print(\"\\nMelhor configuração para o SVM\")\n",
    "print(\"Kernel: \",ker,\" C: \",custo)\n",
    "\n",
    "print(\"\\n\\nDesempenho sobre o conjunto de teste\")\n",
    "SVM = SVC(kernel=ker,C=custo)\n",
    "SVM.fit(x_treino,y_treino)\n",
    "opiniao = SVM.predict(x_teste)\n",
    "print(\"Acurácia sobre o teste: \",accuracy_score(y_teste, opiniao))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicio do código para verificação de melhores parâmetros para classificador MLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maior = -1\n",
    "for i in (5,6,10,12):\n",
    "   for j in ('constant','invscaling', 'adaptive'):\n",
    "      for k in (50,100,150,300,500,1000):\n",
    "        for l in ('identity', 'logistic', 'tanh', 'relu'):\n",
    "            MLP = MLPClassifier(hidden_layer_sizes=(i,i,i), learning_rate=j, max_iter=k, activation=l )\n",
    "            MLP.fit(x_treino,y_treino)\n",
    "\n",
    "            opiniao = MLP.predict(x_validacao)\n",
    "            Acc = accuracy_score(y_validacao, opiniao)\n",
    "            #print(\"Acurácia: \",Acc)\n",
    "\n",
    "            if (Acc > maior):\n",
    "              maior = Acc\n",
    "              Melhor_i = i\n",
    "              Melhor_j = j\n",
    "              Melhor_k = k\n",
    "              Melhor_l = l\n",
    "\n",
    "print(\"Acc do  MLP sobre o conjunto de teste\")\n",
    "MLP = MLPClassifier(hidden_layer_sizes=(Melhor_i,Melhor_i,Melhor_i), learning_rate=Melhor_j, max_iter=Melhor_k, activation=Melhor_l)\n",
    "MLP.fit(x_treino,y_treino)\n",
    "opiniao = MLP.predict(x_teste)\n",
    "Acc = accuracy_score(y_teste, opiniao)\n",
    "print(Acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicio do código para verificação de melhores parâmetros para classificador Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "media = 0 \n",
    "for _ in range(20):\n",
    "    NB = GaussianNB()\n",
    "    NB.fit(x_treino,y_treino)\n",
    "    opiniao = NB.predict(x_validacao)\n",
    "    Acc_validacao = accuracy_score(y_validacao, opiniao)\n",
    "\n",
    "    print(\"Acurácia sobre a validação: \", Acc_validacao)\n",
    "\n",
    "    print(\"\\n\\nDesempenho sobre o conjunto de teste\")\n",
    "\n",
    "    NB = GaussianNB()\n",
    "    NB.fit(x_treino,y_treino)\n",
    "    opiniao = NB.predict(x_teste)\n",
    "    Acc = accuracy_score(y_teste, opiniao)\n",
    "\n",
    "    print(\"\\n\\nAcurácia sobre o teste: \", Acc)\n",
    "    media += Acc\n",
    "\n",
    "print(\"\\n\\nMedia de acurácia do Naive Bayes:\", media/20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
